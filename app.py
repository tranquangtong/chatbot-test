import streamlit as st
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch
from datetime import datetime

# Thi·∫øt l·∫≠p ti√™u ƒë·ªÅ v√† CSS t√πy ch·ªânh - PH·∫¢I ƒê·∫∂T ƒê·∫¶U TI√äN
st.set_page_config(page_title="Chatbot AI", page_icon="ü§ñ")

# CSS t√πy ch·ªânh cho giao di·ªán chat v√† lo·∫°i b·ªè kho·∫£ng tr·∫Øng
st.markdown("""
<style>
/* Lo·∫°i b·ªè padding m·∫∑c ƒë·ªãnh c·ªßa Streamlit */
.block-container {
    padding-top: 1rem !important;
    padding-bottom: 0rem !important;
    margin-top: -2rem;
}

/* Lo·∫°i b·ªè kho·∫£ng tr·∫Øng d∆∞·ªõi ti√™u ƒë·ªÅ */
.stTitle {
    margin-bottom: 0 !important;
    padding-bottom: 0 !important;
}

/* Lo·∫°i b·ªè kho·∫£ng tr·∫Øng gi·ªØa c√°c ph·∫ßn t·ª≠ */
.element-container {
    margin-bottom: 0 !important;
}

/* ƒê·ªãnh d·∫°ng tin nh·∫Øn */
.user-message {
    background-color: #e6f7ff;
    padding: 10px;
    border-radius: 15px 15px 15px 0;
    margin: 5px 0;
    display: flex;
    justify-content: flex-start;
}
.bot-message {
    background-color: #f0f0f0;
    padding: 10px;
    border-radius: 15px 15px 0 15px;
    margin: 5px 0;
    display: flex;
    justify-content: flex-end;
}
.message-container {
    max-width: 80%;
    word-wrap: break-word;
}
.timestamp {
    font-size: 0.8em;
    color: gray;
    margin-top: 5px;
}
.chat-container {
    min-height: 50px;
    max-height: 400px;
    overflow-y: auto;
    padding: 5px;
    border: 1px solid #e6e6e6;
    border-radius: 5px;
    margin-top: 0.5rem;
    margin-bottom: 0.5rem;
}
.main-container {
    display: flex;
    flex-direction: column;
    max-width: 800px;
    margin: 0 auto;
}

/* Gi·∫£m kho·∫£ng c√°ch gi·ªØa c√°c ph·∫ßn t·ª≠ form */
.stForm {
    margin-top: 0.5rem !important;
}
.stForm > div {
    margin-bottom: 0 !important;
}
.stButton {
    margin-top: 0 !important;
}
</style>
""", unsafe_allow_html=True)

# T·∫£i tokenizer v√† m√¥ h√¨nh tr∆∞·ªõc khi kh·ªüi ƒë·ªông ·ª©ng d·ª•ng
@st.cache_resource
def load_model():
    tokenizer = AutoTokenizer.from_pretrained("microsoft/DialoGPT-small")
    model = AutoModelForCausalLM.from_pretrained("microsoft/DialoGPT-small")
    return tokenizer, model

tokenizer, model = load_model()

def chatbot(user_input, chat_history_ids, tokenizer, model):
    # M√£ h√≥a ƒë·∫ßu v√†o c·ªßa ng∆∞·ªùi d√πng
    new_user_input_ids = tokenizer.encode(user_input + tokenizer.eos_token, return_tensors="pt")

    # Th√™m ƒë·∫ßu v√†o c·ªßa ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠ tr√≤ chuy·ªán
    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if chat_history_ids is not None else new_user_input_ids

    # T·∫°o ph·∫£n h·ªìi c·ªßa chatbot
    chat_history_ids = model.generate(
        bot_input_ids,
        max_length=1000,
        pad_token_id=tokenizer.eos_token_id,
        no_repeat_ngram_size=3,
        do_sample=True,
        top_k=100,
        top_p=0.7,
        temperature=0.8
    )

    # Gi·∫£i m√£ ph·∫£n h·ªìi
    response = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)

    return response, chat_history_ids

# Ti√™u ƒë·ªÅ v·ªõi padding nh·ªè h∆°n
st.markdown("<h1 style='margin-bottom:0; padding-bottom:0;'>Chatbot AI ü§ñ</h1>", unsafe_allow_html=True)

# Kh·ªüi t·∫°o l·ªãch s·ª≠ chat trong session state n·∫øu ch∆∞a c√≥
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "chat_history_ids" not in st.session_state:
    st.session_state.chat_history_ids = None

# Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
st.markdown('<div class="chat-container" id="chat-container">', unsafe_allow_html=True)
for message in st.session_state.chat_history:
    if message["role"] == "user":
        st.markdown(f"""
        <div class="user-message">
            <div class="message-container">
                <b>B·∫°n:</b> {message["content"]}
                <div class="timestamp">{message["time"]}</div>
            </div>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown(f"""
        <div class="bot-message">
            <div class="message-container">
                <b>Chatbot:</b> {message["content"]}
                <div class="timestamp">{message["time"]}</div>
            </div>
        </div>
        """, unsafe_allow_html=True)
st.markdown('</div>', unsafe_allow_html=True)

# T·∫°o form nh·∫≠p tin nh·∫Øn v·ªõi padding nh·ªè h∆°n
with st.form(key="message_form", clear_on_submit=True):
    user_input = st.text_input("Nh·∫≠p tin nh·∫Øn c·ªßa b·∫°n:", key="user_input")
    cols = st.columns([4, 1])
    with cols[1]:
        submit_button = st.form_submit_button("G·ª≠i")

# X·ª≠ l√Ω khi ng∆∞·ªùi d√πng g·ª≠i tin nh·∫Øn
if submit_button and user_input:
    # Th√™m tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠
    current_time = datetime.now().strftime("%H:%M")
    st.session_state.chat_history.append({
        "role": "user",
        "content": user_input,
        "time": current_time
    })
    
    # L·∫•y ph·∫£n h·ªìi t·ª´ chatbot
    response, st.session_state.chat_history_ids = chatbot(
        user_input, 
        st.session_state.chat_history_ids, 
        tokenizer, 
        model
    )
    
    # Th√™m ph·∫£n h·ªìi c·ªßa chatbot v√†o l·ªãch s·ª≠
    st.session_state.chat_history.append({
        "role": "bot",
        "content": response,
        "time": current_time
    })
    
    # T·ª± ƒë·ªông rerun ƒë·ªÉ c·∫≠p nh·∫≠t giao di·ªán
    st.rerun()

# JavaScript ƒë·ªÉ cu·ªôn xu·ªëng cu·ªëi c√πng c·ªßa container chat
st.markdown("""
<script>
    function scrollToBottom() {
        var chatContainer = document.getElementById('chat-container');
        if (chatContainer) {
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }
    }
    window.onload = scrollToBottom;
</script>
""", unsafe_allow_html=True)

# Th√™m n√∫t ƒë·ªÉ x√≥a l·ªãch s·ª≠ chat - ƒë·∫∑t ·ªü cu·ªëi v√† nh·ªè h∆°n
col1, col2, col3 = st.columns([1, 1, 1])
with col2:
    if st.button("X√≥a l·ªãch s·ª≠ chat", type="secondary", use_container_width=True):
        st.session_state.chat_history = []
        st.session_state.chat_history_ids = None
        st.rerun()

